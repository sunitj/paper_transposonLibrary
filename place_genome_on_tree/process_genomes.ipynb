{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process genomes using GTDB-tk\n",
    "\n",
    "This notebook first extracts the representative genomes from the zip file generated in the previous step, then processes the genomes using gtdb-tk's `classify_wf`. The output of this step is a summary file that contains the taxonomy of each genome."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Extract representative genomes](#extract-representative-genomes)\n",
    "- [Submit GTDB-tk job](#submit-gtdb-tk-job)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract representative genomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 10:57:38,978\t[INFO]:\tStarting ...\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import logging\n",
    "import shutil\n",
    "import zipfile\n",
    "\n",
    "from cloudpathlib import CloudPath, AnyPath\n",
    "\n",
    "logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format=\"%(asctime)s\\t[%(levelname)s]:\\t%(message)s\",\n",
    ")\n",
    "logging.info(\"Starting ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 10:57:43,394\t[INFO]:\tFound credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "input_dir = AnyPath(\"../data/generated/download_genomes\")\n",
    "output_dir = AnyPath(\"../data/generated/process_genomes\")\n",
    "genomes_zip_file = input_dir / \"genomes.zip\"\n",
    "\n",
    "binqc_s3_basepath = CloudPath(\"s3://genomics-workflow-core/Results/BinQC\")\n",
    "project = \"TransposonLibrary\"\n",
    "prefix = \"20210331\"\n",
    "project_s3_path = binqc_s3_basepath / project / prefix / \"00_genomes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "genomes_dir = output_dir / \"genomes\"\n",
    "# unzip the genomes.zip file\n",
    "with zipfile.ZipFile(genomes_zip_file, \"r\") as zip_ref:\n",
    "    zip_ref.extractall(genomes_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of genomes\n",
    "genomes = list(genomes_dir.rglob(\"*.fna\"))\n",
    "\n",
    "# upload the genomes to s3\n",
    "for genome in genomes:\n",
    "    project_s3_path.joinpath(genome.name).upload_from(genome)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit GTDB-tk job"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This submits a nextflow based job on our AWS Batch environment using the [FischbachLab/nf-binqc](https://github.com/FischbachLab/nf-binqc) github repo. The resulting output contains many qc results, one of which is the GTDB-tk v2.1.1 classify_wf results using the release `release207_v2`.\n",
    "\n",
    "Alternatively, download the GTDB-tk database `release207_v2` to your \"local\" machine. Then run the `classify_wf` locally using the `gtdb_classify_wf.sh` script. Note that running the `classify_wf` locally with the selected options requires at least 320GB of memory, so you may need to use a machine with a lot of memory. I recommend using an `r5.12xlarge` AWS EC2 instance or equivalent.\n",
    "\n",
    "Once teh database has been downloaded, update the `gtdb_classify_wf.sh` script to point to the location of the database. Then run the script as follows:\n",
    "\n",
    "```bash\n",
    "bash -x gtdb_classify_wf.sh genomes_dir\n",
    "```\n",
    "Here `genomes_dir` is the directory containing the representative genomes and expects the genomes with `.fna` extension (can be updated in the bash script)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_batch_job(\n",
    "    project: str,\n",
    "    prefix: str,\n",
    "    fastas: CloudPath,\n",
    "    branch: str = \"main\",\n",
    "    job_queue: str = \"priority-maf-pipelines\",\n",
    "    job_definition: str = \"nextflow-production\",\n",
    "    s3_output_base: CloudPath = CloudPath(\"s3://genomics-workflow-core/Results/BinQC\"),\n",
    "    aws_profile: str = None,\n",
    "    dry_run: bool = False,\n",
    ") -> dict:\n",
    "    \"\"\"Submit a nf-binqc job to AWS Batch\n",
    "    Args:\n",
    "        project (_str_): name of the project\n",
    "        prefix (_str_): name of the sample\n",
    "        fastas (_list_): s3 path to the fastas to be processed\n",
    "        branch (_str_, optional): Branch of nf-binqc to use.\n",
    "            Defaults to \"main\".\n",
    "        job_queue (_str_, optional): name of the queue for the head node.\n",
    "            Defaults to \"priority-maf-pipelines\".\n",
    "        job_definition (_str_, optional): nextflow job definition. Doesn't usually change.\n",
    "            Defaults to \"nextflow-production\".\n",
    "        aws_profile (_str_, optional): if a non-default aws profile should be used to submit jobs.\n",
    "            Defaults to \"None\".\n",
    "        dry_run (_bool_, optional): don't submit the job, just print what the submission command would look like.\n",
    "            Defaults to \"False\".\n",
    "    Returns:\n",
    "        _dict_: a response object that contains details of the job submission from AWS\n",
    "        (https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/batch.html#Batch.Client.submit_job)\n",
    "    \"\"\"\n",
    "    ## Set AWS Profile\n",
    "    if aws_profile is None:\n",
    "        maf = boto3.session.Session()\n",
    "    else:\n",
    "        maf = boto3.session.Session(profile_name=aws_profile)\n",
    "\n",
    "    batch = maf.client(\"batch\")\n",
    "\n",
    "    assert s3_output_base.exists(), f\"{s3_output_base} does not exist\"\n",
    "    assert fastas.exists(), f\"{fastas} does not exist\"\n",
    "\n",
    "    outdir = s3_output_base / project\n",
    "\n",
    "    # Set the pipeline flags for the analysis\n",
    "    command = [\n",
    "        \"FischbachLab/nf-binqc\",\n",
    "        \"-r\",\n",
    "        branch,\n",
    "        \"--project\",\n",
    "        prefix,\n",
    "        \"--fastas\",\n",
    "        fastas.as_uri(),\n",
    "        \"--outdir\",\n",
    "        outdir.as_uri(),\n",
    "    ]\n",
    "\n",
    "    if dry_run:\n",
    "        logging.info(f\"The following command will be run\\n: '{' '.join(command)}'\")\n",
    "        return None\n",
    "\n",
    "    return batch.submit_job(\n",
    "        jobName=f\"nf-bqc-{prefix}\",\n",
    "        jobQueue=job_queue,\n",
    "        jobDefinition=job_definition,\n",
    "        containerOverrides={\"command\": command},\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 11:05:49,782\t[INFO]:\tFound credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'cfb7e0b3-f85c-4071-957f-5931c05a90f5',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'date': 'Fri, 24 Mar 2023 18:05:50 GMT',\n",
       "   'content-type': 'application/json',\n",
       "   'content-length': '165',\n",
       "   'connection': 'keep-alive',\n",
       "   'x-amzn-requestid': 'cfb7e0b3-f85c-4071-957f-5931c05a90f5',\n",
       "   'access-control-allow-origin': '*',\n",
       "   'x-amz-apigw-id': 'CTDzwFLGvHcFxZA=',\n",
       "   'access-control-expose-headers': 'X-amzn-errortype,X-amzn-requestid,X-amzn-errormessage,X-amzn-trace-id,X-amz-apigw-id,date',\n",
       "   'x-amzn-trace-id': 'Root=1-641de67e-58300fde675e3c1312023b1e'},\n",
       "  'RetryAttempts': 0},\n",
       " 'jobArn': 'arn:aws:batch:us-west-2:458432034220:job/db7c6b66-b447-45ee-b13c-d06b97522b34',\n",
       " 'jobName': 'nf-bqc-20210331',\n",
       " 'jobId': 'db7c6b66-b447-45ee-b13c-d06b97522b34'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = submit_batch_job(project=project, prefix=prefix, fastas=project_s3_path)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove the genomes directory\n",
    "shutil.rmtree(genomes_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trees",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
